{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imorting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.patches as patches\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy import interp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>@jamielewislewis i cant believe it, it really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>having a vodka tonic and looking forward to go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>@ddlovatofans1neg1 Could you follow me please....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>@jordanknight for once.................. PLEAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>Had a dream about a walk in fast food resturau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                              tweet\n",
       "0       neg  @jamielewislewis i cant believe it, it really ...\n",
       "1       pos  having a vodka tonic and looking forward to go...\n",
       "2       pos  @ddlovatofans1neg1 Could you follow me please....\n",
       "3       pos  @jordanknight for once.................. PLEAS...\n",
       "4       neg  Had a dream about a walk in fast food resturau..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading data file\n",
    "df =  pd.read_csv( 'sentiment.tsv', header = None, delimiter=\"\\t\")\n",
    "df.columns = ['sentiment', 'tweet']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "          \n",
    "#some spelling correction or converting to meaningful representation. \n",
    "\n",
    "explicit = { \"haven't\": \"have not\",\n",
    "            \"won't\": \"will not\",  \n",
    "            \"i'm\" : \"i am\", \n",
    "            \"didn't\" : \"did not\", \n",
    "            \"don't\" : \"do not\", \n",
    "            \"isn't\" : \"is not\", \n",
    "            \"wasn't\": \"was not\", \n",
    "            \"weren't\" : \"were not\", \n",
    "            \"aren't\" : \"are not\",  \n",
    "            \"couldn't\" : \"could not\",\n",
    "             \"wouldn't\" : \"would not\" , \n",
    "            \"hasn't\" : \"has not\", \n",
    "            \"shalln't\" : \"shall not\", \n",
    "            \"can't\" : \"can not\" , \n",
    "            \"doesn't\" : \"does not\",\n",
    "             \"it's\" : \"it is\",\n",
    "            \"i've\" :\"i have\" ,\n",
    "            \"i'd\" :\"i would\" , \n",
    "            \"he'll\" : \"he will\",\n",
    "            \"she'll\" : \"she will\",\n",
    "            \"you're\" :\"you are\",\n",
    "            \"we're\" :\"we are\",  \n",
    "            \"u're\" : \"you are\",             \n",
    "            \"let's\" : \"let us\" , \n",
    "            \"we'll\" : \"we will\", \n",
    "            \"i'll\" : \"i will\" , \n",
    "            \"you'll\" : \"you will\", \n",
    "            \"that's\" : \"that is\" ,   \n",
    "            \"y'all\" :\"you all\",\n",
    "             \"li'l\" :\"little\",\n",
    "            'ughhh' : 'ugh',\n",
    "            \"suuuupppeeeerrrrr\" : \"super\",    \n",
    "            \"huuurrrttts\" : \"hurts\",\n",
    "            \"grrrrrrrr\" : \"grr\" ,     \n",
    "            \"grrrrrrr\" : \"grr\",          \n",
    "            \"workin\" : \"working\", \n",
    "            \"hear'g\" : \"hearing\", \n",
    "            \"pleanty\" : \"plenty\", \n",
    "            \"suuuupppeeeerrrrr\" : \"super\",     \n",
    "            \"updatessssssssssssssssssssssssssssssssssssssssssssssss\" : \"updates\",\n",
    "           \"u've\" :\"you have\",\n",
    "           \"boredddddddddd\" :\"bored\",\n",
    "           \"daaaaaaang\" :\"dang\",   \n",
    "           \"yeaaaaah\" : \"yeah\",  \n",
    "           \"plllleeeasseee\" :\"please\",\n",
    "           \"yeeeeees\" :\"yes\",\n",
    "           \"yummmmmmmmm\" :\"yummy\",    \n",
    "            \"noooooooooooo\" :\"no\", \n",
    "            \"noooooooooo\" :\"no\",\n",
    "            \"nooooooooo\" :\"no\",    \n",
    "            \"noone\" :\"none\",   \n",
    "            \"nooo\" :\"no\",        \n",
    "            \"hoooooooooooooooooooolla\" :\"hello\",   \n",
    "            \"aaaaaammmazzzingggg\" :\"amazing\",\n",
    "            \"helllllo\" :\"hello\",           \n",
    "            \"loviiiiing\" :\"loving\",\n",
    "            \"xxxxxxxxxx\" : \"xx\",\n",
    "            \"gaaaaaaaaaah\" :\"gah\",\n",
    "            \"gaahhhhh\" :\"gah\", \n",
    "            \"gahh\" :\"gah\",         \n",
    "            \"niceeeeeeeee\" :\"nice\",\n",
    "            \"wellllllll\" :\"well\",      \n",
    "            \"gooooodmorning\" :\"good morning\",\n",
    "            \"loveletter\" : \"love letter\",    \n",
    "            \"betterrrrr\" :\"better\",\n",
    "            \"goooooood\" : \"good\",     \n",
    "            \"wooooow\" :\"wow\",\n",
    "            \"looooove\" :\"love\",\n",
    "            \"luckyyyy\" :\"lucky\", \n",
    "            \"crashiiinnnn\" : \"crashing\",       \n",
    "            \"yearrrr\" : \"year\",\n",
    "            \"overrrr\" : \"over\",   \n",
    "            \"herrrr\" : \"her\",\n",
    "            \"everrr\" : \"ever\" ,     \n",
    "            \"girlllll\" : \"girl\",  \n",
    "            \"alllll\" : \"all\",  \n",
    "            \"alll\" : \"all\",  \n",
    "            \"pleeease\" :\"please\",        \n",
    "            \"historyyyy\" : \"history\", \n",
    "            \"easyyy\" : \"easy\", \n",
    "            \"moreeee\" : \"more\", \n",
    "            \"preetyy\" : \"preety\", \n",
    "            \"lolllll\" : \"lol\",              \n",
    "            \"sweeeet\" : \"sweet\", \n",
    "            \"gr8r\" : \"greater\",         \n",
    "            \"thatsss\" : \"that is\", \n",
    "            \"ggoodd\" : \"good\",\n",
    "            \"omggg\" : \"omg\",\n",
    "            \"destroytwitter\" : \"destroy twitter\", \n",
    "            \"nowww\" :\"now\",      \n",
    "            \"fuckkinq\" :\"fucking\",    \n",
    "            \"worssst\" : \"worst\",\n",
    "            \"lazzzzybum\" : \"lazy bum\",\n",
    "            \"arghhhh\" : \"argh\",   \n",
    "            \"hurtss\" :\"hurts\",  \n",
    "            \"thx\" : \"thanks\",    \n",
    "            \"sickk\" : \"sick\", \n",
    "            \"xxxxxxxxxx\" : \"xx\", \n",
    "            \"knoww\" : \"know\", \n",
    "            \"cryed\" : \"cried\",\n",
    "            \"studiyn\" : \"studying\",\n",
    "            \"badd\" : \"bad\",\n",
    "            \"srry\" : \"sorry\",  \n",
    "            \"ahhhhhhhhhhhhhhh\" : \"ah\",                   \n",
    "            \"ahhhhhhhhhhhh\" : \"ah\", \n",
    "            \"aaahhhhhh\" : \"ah\",           \n",
    "            \"yeahhhh\" : \"yeah\",       \n",
    "            \"ahhhaaa\" : \"ah\",\n",
    "            \"waitiinq\" :\"waiting\",            \n",
    "            \"nighhht\" : \"night\",\n",
    "            \"supportin'\" : \"supporting\",\n",
    "            \"ohwell\" : \"oh well\",  \n",
    "            \"seddd\" : \"said\",\n",
    "            \"thankyou\" : \"thank you\",\n",
    "            \"evenn\" : \"even\",            \n",
    "            \"wayy\" : \"way\",\n",
    "            \"soooooooo\" :\"so\",\n",
    "            \"soooooo\" : \"so\",\n",
    "            \"sooooon\" :\"soon\",\n",
    "            \"soooorry\" :\"sorry\",\n",
    "            \"soooo\" : \"so\",\n",
    "            \"sooo\" :\"so\",         \n",
    "             \"lmaooo\" : \"lmao\", \n",
    "             \"swesome\" : \"awesome\",    \n",
    "            \"doneee\" : \"done\",\n",
    "            \"tummmyyy\" : \"tummy\",\n",
    "            \"quittin'\" : \"quitting\",\n",
    "            \"heeelp\" : \"help\",\n",
    "            \"shortt\" : \"short\",\n",
    "            'yippieee' : 'yippie',\n",
    "            'shaddaaaaap' : 'shut up',\n",
    "            'excitedd' : 'excited',\n",
    "            'iamsoannoyed' : 'i am so annoyed',\n",
    "            'illiegal': 'illegal',\n",
    "            'longg' : 'long',\n",
    "            'ischill' : 'is chill',\n",
    "            'mashallah' : 'God has willed it',\n",
    "            'alhamdulillah' : 'praise be to God',\n",
    "            'saddned' : 'saddened',\n",
    "            'missfabulous' : 'miss fabulous'\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these three lines to do the replacement\n",
    "rep = dict((re.escape(k), v) for k, v in explicit.items()) \n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "\n",
    "stops = set(stopwords.words(\"english\")) #load english words \n",
    "stops -= {'not', 'no', 'none'} #discarding negative terms\n",
    "\n",
    "def review_to_wordlist( review):\n",
    "    review_text = review.lower()\n",
    "    review_text = pattern.sub(lambda m: explicit[re.escape(m.group(0))], review_text)   \n",
    "    review_text = re.sub(r\"\\bshallnt\\b\",  \"shall not\", review_text)\n",
    "    review_text = re.sub(r\"\\bhahah\\b\", \"haha\", review_text)\n",
    "    review_text = re.sub(r\"\\bhahha\\b\", \"haha\", review_text)   \n",
    "    review_text = re.sub(r\"\\bcrampsss\\b\", \"cramps\", review_text)    \n",
    "    review_text = re.sub(r\"\\bboooo\\b\", \"boo\", review_text)\n",
    "    review_text = re.sub(r\"\\bbooo\\b\", \"boo\", review_text)       \n",
    "    review_text = re.sub(r\"\\bwaaaa\\b\", \"wa\", review_text) \n",
    "    review_text = re.sub(r\"\\bgodd\\b\", \"god\", review_text)    \n",
    "    review_text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",review_text).split())\n",
    "    review_text = review_text.strip()\n",
    "    review_text = review_text.split()   \n",
    "    words = [w for w in review_text if not w in stops]    \n",
    "    text = \" \".join(words)\n",
    "    return(text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>@jamielewislewis i cant believe it, it really ...</td>\n",
       "      <td>cant believe really doesnt belong hope doesnt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>having a vodka tonic and looking forward to go...</td>\n",
       "      <td>vodka tonic looking forward going saddle ranch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>@ddlovatofans1neg1 Could you follow me please....</td>\n",
       "      <td>could follow please would really appreciate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>@jordanknight for once.................. PLEAS...</td>\n",
       "      <td>please tell us u thinking person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>Had a dream about a walk in fast food resturau...</td>\n",
       "      <td>dream walk fast food resturaunt sold ice cream...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                              tweet  \\\n",
       "0       neg  @jamielewislewis i cant believe it, it really ...   \n",
       "1       pos  having a vodka tonic and looking forward to go...   \n",
       "2       pos  @ddlovatofans1neg1 Could you follow me please....   \n",
       "3       pos  @jordanknight for once.................. PLEAS...   \n",
       "4       neg  Had a dream about a walk in fast food resturau...   \n",
       "\n",
       "                                    Processed_tweets  \n",
       "0  cant believe really doesnt belong hope doesnt ...  \n",
       "1  vodka tonic looking forward going saddle ranch...  \n",
       "2        could follow please would really appreciate  \n",
       "3                   please tell us u thinking person  \n",
       "4  dream walk fast food resturaunt sold ice cream...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet.iloc[16] = 'inconvenience is regretted' #16th column is hindi\n",
    "df['Processed_tweets'] = df.tweet.apply(lambda x: review_to_wordlist(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict() \n",
    "   \n",
    "f = open('glove.twitter.27B.200d.txt', encoding=\"utf8\")  \n",
    "\n",
    "#getting vectors as value for words as key in the 'embeddings_index' dictionary\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word =  values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting vectors for few words manually\n",
    "embeddings_index[\"fu**ked\"] = embeddings_index[\"fucked\"]\n",
    "embeddings_index[\"fu**king\"] = embeddings_index[\"fucking\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = None)                             \n",
    "dim = 200 #dimension of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "\n",
    "#Tokenzing all tweets to get the words \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Processed_tweets'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "         embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, vocab, embeddings_index):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((dim,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.0\n",
    "    #\n",
    "    # Index2word is a list that contains the names of the words in\n",
    "    # the model's vocabulary. Convert it to a set, for speed\n",
    "    index2word_set = set(vocab)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set and embeddings_index.get(word) is not None:\n",
    "            nwords = nwords + 1.0\n",
    "            featureVec = np.add(featureVec, embeddings_index.get(word))\n",
    "    #\n",
    "    # Divide the result by the number of words to get the average\n",
    "    if nwords > 0.0 :\n",
    "        featureVec = np.divide(featureVec,nwords)\n",
    "    \n",
    "    return (featureVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, vocab,embeddings_index):\n",
    "    # Given a set of reviews (each one a list of words), calculate\n",
    "    # the average feature vector for each one and return a 2D numpy array\n",
    "    #\n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    #\n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews), dim),dtype=\"float32\")\n",
    "    #\n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "        #\n",
    "        # Print a status message every 1000th review\n",
    "        if counter%1000. == 0.:\n",
    "            print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       #\n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "        reviewFeatureVecs[int(counter)] =  makeFeatureVec(review , vocab, embeddings_index)\n",
    "       #\n",
    "       # Increment the counter\n",
    "        counter = counter + 1.\n",
    "        \n",
    "    return (reviewFeatureVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of words in tweets\n",
    "vocab = []\n",
    "\n",
    "for (k,v) in tokenizer.word_index.items():\n",
    "     vocab.append(k)\n",
    "        \n",
    "vocab1 = set(vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 2001\n",
      "Review 1000 of 2001\n",
      "Review 2000 of 2001\n"
     ]
    }
   ],
   "source": [
    "def getCleanReviews(reviews):\n",
    "    clean_reviews = []\n",
    "    for review in reviews[\"Processed_tweets\"]:\n",
    "        clean_reviews.append(review.split(\" \"))\n",
    "    return (clean_reviews)\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( getCleanReviews(df), vocab, embeddings_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 0s 233us/step - loss: 0.6204 - accuracy: 0.6617\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 0s 63us/step - loss: 0.5330 - accuracy: 0.7261\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 0s 64us/step - loss: 0.4948 - accuracy: 0.7639\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 0s 69us/step - loss: 0.4712 - accuracy: 0.7794\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.4523 - accuracy: 0.7850\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4379 - accuracy: 0.7956\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 0s 72us/step - loss: 0.4287 - accuracy: 0.7978\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4119 - accuracy: 0.8100\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 0s 72us/step - loss: 0.4026 - accuracy: 0.8150\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 0s 72us/step - loss: 0.3918 - accuracy: 0.8233\n",
      "1\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 0s 225us/step - loss: 0.6276 - accuracy: 0.6489\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 0s 77us/step - loss: 0.5276 - accuracy: 0.7467\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 0s 78us/step - loss: 0.4866 - accuracy: 0.7672\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 0s 80us/step - loss: 0.4700 - accuracy: 0.7728\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 0s 77us/step - loss: 0.4511 - accuracy: 0.7783\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4366 - accuracy: 0.7889\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.4255 - accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 0s 74us/step - loss: 0.4144 - accuracy: 0.8067\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4031 - accuracy: 0.8189\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 0s 76us/step - loss: 0.3956 - accuracy: 0.8194\n",
      "2\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 1s 332us/step - loss: 0.6344 - accuracy: 0.6428\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 0s 165us/step - loss: 0.5399 - accuracy: 0.7383\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 0s 148us/step - loss: 0.4984 - accuracy: 0.7517\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 0s 86us/step - loss: 0.4744 - accuracy: 0.7656\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 0s 83us/step - loss: 0.4569 - accuracy: 0.7817\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 0s 85us/step - loss: 0.4424 - accuracy: 0.7850\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 0s 79us/step - loss: 0.4331 - accuracy: 0.7939\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 0s 90us/step - loss: 0.4198 - accuracy: 0.7967\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4057 - accuracy: 0.8122\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 0s 65us/step - loss: 0.3958 - accuracy: 0.8167\n",
      "3\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 0s 263us/step - loss: 0.6074 - accuracy: 0.6722\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 0s 68us/step - loss: 0.5239 - accuracy: 0.7317\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4872 - accuracy: 0.7633\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.4693 - accuracy: 0.7733\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.4553 - accuracy: 0.7783\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 0s 70us/step - loss: 0.4416 - accuracy: 0.7878\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.4295 - accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 0s 71us/step - loss: 0.4149 - accuracy: 0.8094\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 0s 69us/step - loss: 0.4044 - accuracy: 0.8089\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 0s 72us/step - loss: 0.3944 - accuracy: 0.8183\n",
      "4\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 0s 258us/step - loss: 0.6035 - accuracy: 0.6872\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 0s 70us/step - loss: 0.5141 - accuracy: 0.7511\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 0s 71us/step - loss: 0.4779 - accuracy: 0.7706\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 0s 77us/step - loss: 0.4573 - accuracy: 0.7867\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.4436 - accuracy: 0.7933\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4326 - accuracy: 0.8017\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 0s 76us/step - loss: 0.4210 - accuracy: 0.8011\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 0s 77us/step - loss: 0.4094 - accuracy: 0.8128\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.3978 - accuracy: 0.8144\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 0s 73us/step - loss: 0.3878 - accuracy: 0.8194\n",
      "5\n",
      "Epoch 1/10\n",
      "1801/1801 [==============================] - 0s 266us/step - loss: 0.6262 - accuracy: 0.6507\n",
      "Epoch 2/10\n",
      "1801/1801 [==============================] - 0s 48us/step - loss: 0.5285 - accuracy: 0.7390\n",
      "Epoch 3/10\n",
      "1801/1801 [==============================] - 0s 44us/step - loss: 0.4894 - accuracy: 0.7607\n",
      "Epoch 4/10\n",
      "1801/1801 [==============================] - 0s 68us/step - loss: 0.4660 - accuracy: 0.7779\n",
      "Epoch 5/10\n",
      "1801/1801 [==============================] - 0s 75us/step - loss: 0.4515 - accuracy: 0.7857\n",
      "Epoch 6/10\n",
      "1801/1801 [==============================] - 0s 77us/step - loss: 0.4333 - accuracy: 0.7923\n",
      "Epoch 7/10\n",
      "1801/1801 [==============================] - 0s 73us/step - loss: 0.4234 - accuracy: 0.8018\n",
      "Epoch 8/10\n",
      "1801/1801 [==============================] - 0s 80us/step - loss: 0.4106 - accuracy: 0.8068\n",
      "Epoch 9/10\n",
      "1801/1801 [==============================] - 0s 76us/step - loss: 0.3955 - accuracy: 0.8168\n",
      "Epoch 10/10\n",
      "1801/1801 [==============================] - 0s 76us/step - loss: 0.3879 - accuracy: 0.8223\n",
      "6\n",
      "Epoch 1/10\n",
      "1802/1802 [==============================] - 1s 331us/step - loss: 0.6053 - accuracy: 0.6743\n",
      "Epoch 2/10\n",
      "1802/1802 [==============================] - 0s 130us/step - loss: 0.5135 - accuracy: 0.7492\n",
      "Epoch 3/10\n",
      "1802/1802 [==============================] - 0s 118us/step - loss: 0.4737 - accuracy: 0.7691\n",
      "Epoch 4/10\n",
      "1802/1802 [==============================] - 0s 77us/step - loss: 0.4520 - accuracy: 0.7830\n",
      "Epoch 5/10\n",
      "1802/1802 [==============================] - 0s 82us/step - loss: 0.4311 - accuracy: 0.7919\n",
      "Epoch 6/10\n",
      "1802/1802 [==============================] - 0s 77us/step - loss: 0.4189 - accuracy: 0.7952\n",
      "Epoch 7/10\n",
      "1802/1802 [==============================] - 0s 75us/step - loss: 0.4075 - accuracy: 0.8119\n",
      "Epoch 8/10\n",
      "1802/1802 [==============================] - 0s 73us/step - loss: 0.3915 - accuracy: 0.8219\n",
      "Epoch 9/10\n",
      "1802/1802 [==============================] - 0s 79us/step - loss: 0.3795 - accuracy: 0.8263\n",
      "Epoch 10/10\n",
      "1802/1802 [==============================] - 0s 79us/step - loss: 0.3695 - accuracy: 0.8368\n",
      "7\n",
      "Epoch 1/10\n",
      "1802/1802 [==============================] - 1s 319us/step - loss: 0.6266 - accuracy: 0.6632\n",
      "Epoch 2/10\n",
      "1802/1802 [==============================] - 0s 134us/step - loss: 0.5359 - accuracy: 0.7408\n",
      "Epoch 3/10\n",
      "1802/1802 [==============================] - 0s 115us/step - loss: 0.4967 - accuracy: 0.7619\n",
      "Epoch 4/10\n",
      "1802/1802 [==============================] - 0s 78us/step - loss: 0.4711 - accuracy: 0.7703\n",
      "Epoch 5/10\n",
      "1802/1802 [==============================] - 0s 77us/step - loss: 0.4532 - accuracy: 0.7913\n",
      "Epoch 6/10\n",
      "1802/1802 [==============================] - 0s 75us/step - loss: 0.4433 - accuracy: 0.7963\n",
      "Epoch 7/10\n",
      "1802/1802 [==============================] - 0s 78us/step - loss: 0.4263 - accuracy: 0.8008\n",
      "Epoch 8/10\n",
      "1802/1802 [==============================] - 0s 78us/step - loss: 0.4193 - accuracy: 0.8030\n",
      "Epoch 9/10\n",
      "1802/1802 [==============================] - 0s 75us/step - loss: 0.4076 - accuracy: 0.8141\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1802/1802 [==============================] - 0s 78us/step - loss: 0.3931 - accuracy: 0.8191\n",
      "8\n",
      "Epoch 1/10\n",
      "1802/1802 [==============================] - 1s 280us/step - loss: 0.6165 - accuracy: 0.6715\n",
      "Epoch 2/10\n",
      "1802/1802 [==============================] - 0s 74us/step - loss: 0.5265 - accuracy: 0.7519\n",
      "Epoch 3/10\n",
      "1802/1802 [==============================] - 0s 76us/step - loss: 0.4880 - accuracy: 0.7719\n",
      "Epoch 4/10\n",
      "1802/1802 [==============================] - 0s 77us/step - loss: 0.4699 - accuracy: 0.7741\n",
      "Epoch 5/10\n",
      "1802/1802 [==============================] - 0s 71us/step - loss: 0.4506 - accuracy: 0.7747\n",
      "Epoch 6/10\n",
      "1802/1802 [==============================] - 0s 74us/step - loss: 0.4398 - accuracy: 0.7902\n",
      "Epoch 7/10\n",
      "1802/1802 [==============================] - 0s 72us/step - loss: 0.4260 - accuracy: 0.7947\n",
      "Epoch 8/10\n",
      "1802/1802 [==============================] - 0s 71us/step - loss: 0.4099 - accuracy: 0.8130\n",
      "Epoch 9/10\n",
      "1802/1802 [==============================] - 0s 72us/step - loss: 0.4020 - accuracy: 0.8074\n",
      "Epoch 10/10\n",
      "1802/1802 [==============================] - 0s 72us/step - loss: 0.3886 - accuracy: 0.8241\n",
      "9\n",
      "Epoch 1/10\n",
      "1802/1802 [==============================] - 1s 340us/step - loss: 0.6204 - accuracy: 0.6670\n",
      "Epoch 2/10\n",
      "1802/1802 [==============================] - 0s 149us/step - loss: 0.5214 - accuracy: 0.7386\n",
      "Epoch 3/10\n",
      "1802/1802 [==============================] - 0s 151us/step - loss: 0.4830 - accuracy: 0.7614\n",
      "Epoch 4/10\n",
      "1802/1802 [==============================] - 0s 129us/step - loss: 0.4590 - accuracy: 0.7747\n",
      "Epoch 5/10\n",
      "1802/1802 [==============================] - 0s 53us/step - loss: 0.4440 - accuracy: 0.7875\n",
      "Epoch 6/10\n",
      "1802/1802 [==============================] - 0s 76us/step - loss: 0.4299 - accuracy: 0.7986\n",
      "Epoch 7/10\n",
      "1802/1802 [==============================] - 0s 79us/step - loss: 0.4174 - accuracy: 0.8036\n",
      "Epoch 8/10\n",
      "1802/1802 [==============================] - 0s 77us/step - loss: 0.4048 - accuracy: 0.8141\n",
      "Epoch 9/10\n",
      "1802/1802 [==============================] - 0s 92us/step - loss: 0.3933 - accuracy: 0.8219\n",
      "Epoch 10/10\n",
      "1802/1802 [==============================] - 0s 79us/step - loss: 0.3823 - accuracy: 0.8241\n",
      "10\n",
      "0.8309166340803749\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10,shuffle=False) #initiate k-fold cross validation object\n",
    "\n",
    "feeling = {'pos': 1,'neg': 0}\n",
    "df['newfeeling'] = [feeling[item] for item in df.sentiment] #converting 'sentiment' class to numeric\n",
    "\n",
    "aucs = [] #store auc of each fold \n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "i = 1\n",
    "x = pd.DataFrame(trainDataVecs)\n",
    "y = df['newfeeling']\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "for train,test in cv.split(x,y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(80, activation='relu', input_dim=200))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x.iloc[train],y.iloc[train], batch_size= 32, epochs = 10, shuffle=True) #fitting the NN model on \n",
    "    #this particular training fold     \n",
    "    prediction = model.predict(x.iloc[test]) #and get the probabilities for test fold\n",
    "    lst_prediction = list(chain.from_iterable(prediction))\n",
    "    fpr, tpr, t = roc_curve(y[test], lst_prediction) #get false positive rate, true positive rate and thresholds\n",
    "    roc_auc = auc(fpr, tpr) #get auc for this particular fold\n",
    "    aucs.append(roc_auc)\n",
    "    print(i)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i= i+1\n",
    "    \n",
    "print(np.mean(aucs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
